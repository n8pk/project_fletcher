{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "import string\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the MVP, files stored in '/mvp_reviews'\n",
    "\n",
    "48 strains x 104 reviews (Leafly is into multiples of 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_reviews = pd.read_pickle('pkl/mvp_reviews.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unpack and check raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the way I've stored the reviews is in one large list of lists\n",
    "\n",
    "we'll unpack this, but first a quick peek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stored_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's just look at the first review of the first strain...\n",
    "\n",
    "we're concerned with formatting, thankfully everything is already text because of the way we scraped it\n",
    "\n",
    "however, we still have: numbers, punctuation, capitalization, interesting vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Friends, stoners, red-eyed countrymen, lend me your ears; for I bring unto thee a tale of the Blue Dream... T’was a calm April night, 2014 it was, and I had eagerly purchased an eighth of some pungent Blue Dream. It’s abundance of sugary trichomes, paired with the thick density of the bud was enough to bring a tear to your eye. I enthusiastically ground up the cheeba, packed a generous bowl and went to town. Eight minutes and a bowl later, I was beginning to assume that my herb wasn’t all that strong…but then it hit me like a 150-ton locomotive of euphoria. “Whoooa” was the only thing that I could say, as I looked at everything around the living room. Everything looked as if it were lagging behind by a few frames, and this cerebral adventure lasted for the first few minutes…but just when I thought that Blue Dream had shown me everything there was to experience about her, her sativa effects began to kick in. All of a sudden, I felt as if I was briskly cruising on a warm cloud, which was followed by an amazing burst of energy. Folks let me tell you, if you’d ever like to find out how an eagle feels when it spreads its majestic wings and takes to the air at 80 mph., this strain is a kickass tool to take you there. Finally, when all of your euphoric energy has been expended, Blue Dream ends her experience with a mellow cruise induced by her indica side. Call in at Jimmy John’s and order 12 sandwiches, fire up Netflix, and take it easy on the couch until you slowly begin to melt into the furniture, because you're going to start to drift off into your happy place; and as soon as you reach that critical point of relaxation, you’re going to sleep like a sloth on twelve doses of Ambien. Folks, I guess the moral of the story here is that Blue Dream is an outstanding and pleasurable strain that is fun for cannabis enthusiasts anywhere on the experience spectrum; from the novice user who is looking to have an easy-going yet memorable experience, to the seasoned smoker who owns a laser pointer and a cat, and anybody in between; but my review alone can’t depict the exquisite effects that Blue Dream has to offer. Roll up a liberal amount of Blue Dream, spark it up, and let her take you on a spectacular trip; you’ll be thankful you did when your mind is blissfully floating through the heavens.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stored_reviews[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's explore a couple different ways to handle cleaning\n",
    "\n",
    "remove = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "\n",
    "clean_list = []\n",
    "for inner in stored_reviews:\n",
    "    strain = ''\n",
    "    \n",
    "    for review in inner:\n",
    "        review = review.translate(remove) # translate runs on C, so it's fast, really fast\n",
    "        # join is another quick function, but not quite as efficient, here's an interpretable implementation using a list comprehension\n",
    "        review = ''.join([i for i in review if not i.isdigit()]) \n",
    "        strain += review.lower()\n",
    "        \n",
    "    clean_list.append(strain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we have text that's ready to see some stronger stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'friends stoners redeyed countrymen lend me your ears for i bring unto thee a tale of the blue dream '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_list[0][:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exploring spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spacy is excellent! after spending some time scouring the docs, I came across quite a few practical examples\n",
    "\n",
    "first let's get all of the documents into a format we can clean and lemmatize\n",
    "\n",
    "lemmatization is the process of turning words into their root, so ['describe', 'described', 'describes'] all become 'describe'\n",
    "\n",
    "this first cell where we call nlp is the bulk of the work\n",
    "\n",
    "cleaning was fast, but we need something we can throw into a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(token):\n",
    "    \n",
    "    '''\n",
    "    for each token, determine if it's noise\n",
    "    \n",
    "    i.e. if it's a stopword, too short, or punctuation\n",
    "    '''\n",
    "    \n",
    "    noise = False\n",
    "    if token.is_stop == True:\n",
    "        noise = True\n",
    "    elif token.is_punct == True:\n",
    "        noise = True\n",
    "    elif token.is_digit == True:\n",
    "        noise = True\n",
    "    elif token.is_space == True:\n",
    "        noise = True\n",
    "    elif len(token) < 3:\n",
    "        noise = True\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_reviews = []\n",
    "\n",
    "for strain in clean_list:\n",
    "    tokenized_strain = nlp(strain)\n",
    "    strain_review = ''\n",
    "    for token in tokenized_strain:\n",
    "        if noise(token):\n",
    "            pass\n",
    "        else:\n",
    "            strain_review += str(token.lemma_) + ' '\n",
    "            \n",
    "    tokenized_reviews.append(strain_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'friend stoner redey countryman lend ear bring unto thee tale blue dream t’wa calm april night eagerl'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_reviews[0][:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our data is almost ready for some machine learning!\n",
    "\n",
    "now we need to split every word into it's own place\n",
    "\n",
    "the result is one massive list of lists (again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed = []\n",
    "\n",
    "for review in tokenized_reviews:\n",
    "    \n",
    "    preprocessed.append(review.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['friend',\n",
       " 'stoner',\n",
       " 'redey',\n",
       " 'countryman',\n",
       " 'lend',\n",
       " 'ear',\n",
       " 'bring',\n",
       " 'unto',\n",
       " 'thee',\n",
       " 'tale',\n",
       " 'blue',\n",
       " 'dream',\n",
       " 't’wa',\n",
       " 'calm',\n",
       " 'april',\n",
       " 'night',\n",
       " 'eagerly',\n",
       " 'purchase',\n",
       " 'eighth',\n",
       " 'pungent']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out = open('mvp_preprocessed.pkl', 'wb')\n",
    "pickle.dump(preprocessed, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
