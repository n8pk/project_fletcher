{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gensim format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_filtered = [strain.split() for strain in name_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-06 12:15:52,425 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2018-03-06 12:15:52,720 : INFO : built Dictionary(14063 unique tokens: ['able', 'absolute', 'absolutely', 'abundance', 'abuse']...) from 48 documents (total 150080 corpus positions)\n",
      "2018-03-06 12:15:52,768 : INFO : discarding 11119 tokens: [('able', 43), ('absolutely', 46), ('abuse', 2), ('accept', 2), ('acrylic', 1), ('active', 32), ('activity', 30), ('actually', 41), ('add', 32), ('addiction', 2)]...\n",
      "2018-03-06 12:15:52,774 : INFO : keeping 2944 tokens which were in no less than 3 and no more than 28 (=60.0%) documents\n",
      "2018-03-06 12:15:52,797 : INFO : resulting dictionary: Dictionary(2944 unique tokens: ['absolute', 'abundance', 'accomplish', 'accurate', 'accurately']...)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(2944 unique tokens: ['absolute', 'abundance', 'accomplish', 'accurate', 'accurately']...)\n"
     ]
    }
   ],
   "source": [
    "# building a dictionary, and clearing outliers\n",
    "\n",
    "words = corpora.Dictionary(gen_filtered)\n",
    "words.filter_extremes(no_below=3, no_above=.6)\n",
    "words.compactify()\n",
    "\n",
    "corpus = [words.doc2bow(text) for text in gen_filtered]\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-06 09:41:22,642 : INFO : collecting all words and their counts\n",
      "2018-03-06 09:41:22,645 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-03-06 09:41:22,708 : INFO : collected 14063 word types from a corpus of 150080 raw words and 48 sentences\n",
      "2018-03-06 09:41:22,710 : INFO : Loading a fresh vocabulary\n",
      "2018-03-06 09:41:22,859 : INFO : min_count=10 retains 1763 unique words (12% of original 14063, drops 12300)\n",
      "2018-03-06 09:41:22,860 : INFO : min_count=10 leaves 125985 word corpus (83% of original 150080, drops 24095)\n",
      "2018-03-06 09:41:22,881 : INFO : deleting the raw counts dictionary of 14063 items\n",
      "2018-03-06 09:41:22,886 : INFO : sample=0.001 downsamples 71 most-common words\n",
      "2018-03-06 09:41:22,888 : INFO : downsampling leaves estimated 105096 word corpus (83.4% of prior 125985)\n",
      "2018-03-06 09:41:22,902 : INFO : estimated required memory for 1763 words and 100 dimensions: 2291900 bytes\n",
      "2018-03-06 09:41:22,910 : INFO : resetting layer weights\n",
      "2018-03-06 09:41:22,981 : INFO : training model with 3 workers on 1763 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=2\n",
      "2018-03-06 09:41:23,366 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-06 09:41:23,389 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-06 09:41:23,409 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-06 09:41:23,411 : INFO : EPOCH - 1 : training on 150080 raw words (105115 effective words) took 0.4s, 247297 effective words/s\n",
      "2018-03-06 09:41:23,787 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-06 09:41:23,798 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-06 09:41:23,805 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-06 09:41:23,809 : INFO : EPOCH - 2 : training on 150080 raw words (105158 effective words) took 0.4s, 272993 effective words/s\n",
      "2018-03-06 09:41:24,128 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-06 09:41:24,137 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-06 09:41:24,149 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-06 09:41:24,151 : INFO : EPOCH - 3 : training on 150080 raw words (105080 effective words) took 0.3s, 315145 effective words/s\n",
      "2018-03-06 09:41:24,597 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-06 09:41:24,617 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-06 09:41:24,623 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-06 09:41:24,625 : INFO : EPOCH - 4 : training on 150080 raw words (105057 effective words) took 0.5s, 227245 effective words/s\n",
      "2018-03-06 09:41:24,934 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-06 09:41:24,958 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-06 09:41:24,960 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-06 09:41:24,962 : INFO : EPOCH - 5 : training on 150080 raw words (105256 effective words) took 0.3s, 315561 effective words/s\n",
      "2018-03-06 09:41:24,964 : INFO : training on a 750400 raw words (525666 effective words) took 2.0s, 265314 effective words/s\n"
     ]
    }
   ],
   "source": [
    "w2v = models.Word2Vec(gen_filtered, size=100, window=2, min_count=10, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nate/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/nate/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n",
      "/home/nate/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "sativa = w2v.most_similar('happy', topn=100)\n",
    "indica = w2v.most_similar('night', topn=100)\n",
    "pain = w2v.most_similar('cbd', topn=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "sativa_neighbors = ['happy']\n",
    "indica_neighbors = ['night']\n",
    "pain_neighbors = ['cbd']\n",
    "\n",
    "for i in range(100):\n",
    "    sativa_neighbors.append(sativa[i][0])\n",
    "    indica_neighbors.append(indica[i][0])\n",
    "    pain_neighbors.append(pain[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1763"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2v.wv.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strain2gram(strain, two_grams):\n",
    "    \n",
    "    \n",
    "    strain_filtered = []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nate/anaconda/lib/python3.6/site-packages/gensim/models/doc2vec.py:359: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "2018-03-06 12:04:46,163 : INFO : collecting all words and their counts\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'words'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-95a6fa6d75a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDoc2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_filtered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, documents, dm_mean, dm, dbow_words, dm_concat, dm_tag_count, docvecs, docvecs_mapfile, comment, trim_rule, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGeneratorType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You can't pass a generator as the documents argument. Try an iterator.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m             self.train(\n\u001b[1;32m    398\u001b[0m                 \u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, documents, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m         \"\"\"\n\u001b[1;32m    721\u001b[0m         total_words, corpus_count = self.vocabulary.scan_vocab(\n\u001b[0;32m--> 722\u001b[0;31m             documents, self.docvecs, progress_per=progress_per, trim_rule=trim_rule)\n\u001b[0m\u001b[1;32m    723\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         report_values = self.vocabulary.prepare_vocab(\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mscan_vocab\u001b[0;34m(self, documents, docvecs, progress_per, trim_rule)\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdocument_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchecked_string_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m                     logger.warning(\n\u001b[1;32m    804\u001b[0m                         \u001b[0;34m\"Each 'words' should be a list of words (usually unicode strings). \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'words'"
     ]
    }
   ],
   "source": [
    "d2v = models.Doc2Vec(gen_filtered, size=100, window=2, min_count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "type1 = ['sativa dominant', 'happy high', 'long time', 'great high', 'anxiety depression',\n",
    "         'wake bake', 'look like', 'strong sativa', 'sativa effect', 'far good']\n",
    "type2 = ['high cbd', 'chronic pain', 'panic attack', 'high thc', 'like smoke',\n",
    "         'decide try', 'anxiety depression', 'anxiety paranoia', 'physical pain', 'taste good']\n",
    "type3 = ['night time', 'fall asleep', 'body stone', 'good night',' melt away',\n",
    "         'great pain', 'night sleep', 'body buzz', 'anxiety insomnia', 'sweet berry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g2v.most_similar('happy high', topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4152"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_g2v = [gram.replace(' ', '') for gram in vectorizer.get_feature_names()]\n",
    "len(load_g2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ablecalm',\n",
       " 'ableeat',\n",
       " 'ableenjoy',\n",
       " 'ablefinish',\n",
       " 'ablefocus',\n",
       " 'ablefunction',\n",
       " 'ablegood',\n",
       " 'ablehandle',\n",
       " 'ablepick',\n",
       " 'ablerelax']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_g2v[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': <gensim.models.keyedvectors.Vocab at 0x7fad3aa14da0>,\n",
       " 'b': <gensim.models.keyedvectors.Vocab at 0x7fad3aa14e80>,\n",
       " 'c': <gensim.models.keyedvectors.Vocab at 0x7fad3aa14e48>,\n",
       " 'd': <gensim.models.keyedvectors.Vocab at 0x7fad3aa0c400>,\n",
       " 'e': <gensim.models.keyedvectors.Vocab at 0x7fad3aa14ef0>,\n",
       " 'f': <gensim.models.keyedvectors.Vocab at 0x7fad8064a400>,\n",
       " 'g': <gensim.models.keyedvectors.Vocab at 0x7fad3aa0ccf8>,\n",
       " 'h': <gensim.models.keyedvectors.Vocab at 0x7fad83f35f60>,\n",
       " 'i': <gensim.models.keyedvectors.Vocab at 0x7fad3f083080>,\n",
       " 'j': <gensim.models.keyedvectors.Vocab at 0x7fad3aa14dd8>,\n",
       " 'k': <gensim.models.keyedvectors.Vocab at 0x7fad3aa0c358>,\n",
       " 'l': <gensim.models.keyedvectors.Vocab at 0x7fad3aa14eb8>,\n",
       " 'm': <gensim.models.keyedvectors.Vocab at 0x7fad3aa14f60>,\n",
       " 'n': <gensim.models.keyedvectors.Vocab at 0x7fad3aa14f98>,\n",
       " 'o': <gensim.models.keyedvectors.Vocab at 0x7fad3ba9b588>,\n",
       " 'p': <gensim.models.keyedvectors.Vocab at 0x7fad3aa0c470>,\n",
       " 'q': <gensim.models.keyedvectors.Vocab at 0x7fad3aa0c668>,\n",
       " 'r': <gensim.models.keyedvectors.Vocab at 0x7fad3aa0c3c8>,\n",
       " 's': <gensim.models.keyedvectors.Vocab at 0x7fad3f083208>,\n",
       " 't': <gensim.models.keyedvectors.Vocab at 0x7fad3aa14f28>,\n",
       " 'u': <gensim.models.keyedvectors.Vocab at 0x7fad5bf68320>,\n",
       " 'v': <gensim.models.keyedvectors.Vocab at 0x7fad3aa0c4a8>,\n",
       " 'w': <gensim.models.keyedvectors.Vocab at 0x7fad3aa0c588>,\n",
       " 'x': <gensim.models.keyedvectors.Vocab at 0x7fad3aa0c7b8>,\n",
       " 'y': <gensim.models.keyedvectors.Vocab at 0x7fad3a7fff60>,\n",
       " 'z': <gensim.models.keyedvectors.Vocab at 0x7fad3aa0c630>}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g2v.wv.vocab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
